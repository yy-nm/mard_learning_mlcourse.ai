{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline 0.95214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit Tf-Idf 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Correct time-aware cross-validation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# Convert time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Look at the first rows of the training set\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites].fillna(0).astype('int').to_csv('train_sessions_text.txt', \n",
    "                                               sep=' ', index=None, header=None)\n",
    "test_df[sites].fillna(0).astype('int').to_csv('test_sessions_text.txt', \n",
    "                                              sep=' ', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 55 0 0 0 0 0 0 0 0\n",
      "56 55 56 55 0 0 0 0 0 0\n",
      "946 946 951 946 946 945 948 784 949 946\n",
      "945 948 949 948 945 946 947 945 946 946\n",
      "947 950 948 947 950 952 946 951 946 947\n"
     ]
    }
   ],
   "source": [
    "!head -5 train_sessions_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "with open('train_sessions_text.txt') as inp_train_file:\n",
    "    X_train = cv.fit_transform(inp_train_file)\n",
    "with open('test_sessions_text.txt') as inp_test_file:\n",
    "    X_test = cv.transform(inp_test_file)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((23051,), (23051,)),\n",
       " ((46102,), (23051,)),\n",
       " ((69153,), (23051,)),\n",
       " ((92204,), (23051,)),\n",
       " ((115255,), (23051,)),\n",
       " ((138306,), (23051,)),\n",
       " ((161357,), (23051,)),\n",
       " ((184408,), (23051,)),\n",
       " ((207459,), (23051,)),\n",
       " ((230510,), (23051,))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(el[0].shape, el[1].shape) for el in time_split.split(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
    "#                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred, 'subm1.csv') # 0.91288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df, X_sparse):\n",
    "    hour = df['time1'].apply(lambda ts: ts.hour)\n",
    "    morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "    night = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "    X = hstack([X_sparse, morning.values.reshape(-1, 1), \n",
    "                day.values.reshape(-1, 1), evening.values.reshape(-1, 1), \n",
    "                night.values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_new = add_time_features(train_df.fillna(0), X_train)\n",
    "X_test_new = add_time_features(test_df.fillna(0), X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 50004), (82797, 50004))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape, X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#cv_scores = cross_val_score(logit, X_train_new, y_train, cv=time_split, \n",
    "#                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred2 = logit.predict_proba(X_test_new)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred2, 'subm2.csv') # 0.93843\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_values = np.logspace(-2, 2, 10)\n",
    "\n",
    "#logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "#                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher.best_score_, logit_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred3 = logit_grid_searcher.predict_proba(X_test_new)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred3, 'subm3.csv') # 0.94242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_features(df, X_sparse):\n",
    "    day = df['time1'].apply(lambda ts: ts.weekday())\n",
    "    weekend = ((day >= 5)).astype('int')\n",
    "    weekday = ((day < 5)).astype('int')\n",
    "    X = hstack([X_sparse, weekend.values.reshape(-1, 1), \n",
    "                weekday.values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_new1 = add_time_features(train_df.fillna(0), X_train_new)\n",
    "X_test_new1 = add_time_features(test_df.fillna(0), X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_new1.shape, X_test_new1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#cv_scores = cross_val_score(logit, X_train_new1, y_train, cv=time_split, \n",
    "#                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_scores, cv_scores.mean()\n",
    "# 0.9164082065409461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher.fit(X_train_new1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher.best_score_, logit_grid_searcher.best_params_\n",
    "# (0.9183503264075926, {'C': 0.21544346900318834})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred4 = logit_grid_searcher.predict_proba(X_test_new1)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred4, 'subm_self1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_unique_site_sum(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            s.add(row[i])\n",
    "            pass\n",
    "        pass\n",
    "    return sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_unique_site(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            s.add(row[i])\n",
    "            pass\n",
    "        pass\n",
    "    return len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_unique_site_sum(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            s.add(row[i])\n",
    "            pass\n",
    "        pass\n",
    "    return sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_unique_site(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            s.add(row[i])\n",
    "            pass\n",
    "        pass\n",
    "    return len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### no more use the original data nummber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_web_statistic = {}\n",
    "alice_web_count_statistic = {}\n",
    "\n",
    "def getalice_feature(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        webid = row[i]\n",
    "        s.add(webid)\n",
    "        if webid in alice_web_statistic:\n",
    "            alice_web_statistic[webid] = alice_web_statistic[webid] + 1\n",
    "        else:\n",
    "            alice_web_statistic[webid] = 1\n",
    "            pass\n",
    "        pass\n",
    "    webcount = len(s)\n",
    "    if webcount in alice_web_count_statistic:\n",
    "        alice_web_count_statistic[webcount] = alice_web_count_statistic[webcount] + 1\n",
    "    else:\n",
    "        alice_web_count_statistic[webcount] = 1\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "#train_df[train_df['target'] == 1][sites].fillna(0).astype('int').apply(lambda row: getalice_feature(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_web_count_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_web_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_web_count = [(k, alice_web_count_statistic[k]) for k in sorted(alice_web_count_statistic, key=alice_web_count_statistic.get, reverse=True)][: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_love_web = [(k, alice_web_statistic[k]) for k in sorted(alice_web_statistic, key=alice_web_statistic.get, reverse=True)][: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_web_statistic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_alice_love_web(row):\n",
    "    count = 0\n",
    "    for i in sites:\n",
    "        if row[i] in alice_love_web:\n",
    "            count += 1\n",
    "            pass\n",
    "        pass\n",
    "    return count > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_alice_web_count(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            s.add(row[i])\n",
    "            pass\n",
    "        pass\n",
    "    return sum(s) in alice_web_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features8(df, X_sparse):\n",
    "    hour = df['time1'].apply(lambda ts: ts.hour)\n",
    "    morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "    night = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "    \n",
    "    dayinweek = df['time1'].apply(lambda ts: ts.weekday())\n",
    "    weekend = ((dayinweek >= 5)).astype('int')\n",
    "    weekday = ((dayinweek < 5)).astype('int')\n",
    "    \n",
    "    web_count_match = df.apply (lambda row: match_alice_web_count (row),axis=1).astype('int')\n",
    "    \n",
    "    web_type = df.apply (lambda row: match_alice_love_web (row),axis=1)\n",
    "   \n",
    "    \n",
    "    X = hstack([X_sparse, morning.values.reshape(-1, 1), \n",
    "                day.values.reshape(-1, 1), evening.values.reshape(-1, 1), \n",
    "                night.values.reshape(-1, 1)\n",
    "                , weekend.values.reshape(-1, 1)\n",
    "                , weekday.values.reshape(-1, 1)\n",
    "                , web_count_match.values.reshape(-1, 1)\n",
    "                , web_type.values.reshape(-1, 1)\n",
    "               ])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#X_train_new8 = add_features8(train_df.fillna(0), X_train)\n",
    "#X_test_new8 = add_features8(test_df.fillna(0), X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#cv_scores = cross_val_score(fastlogist, X_train_new8, y_train, cv=time_split, \n",
    "#                            scoring='scoring ', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_scores, cv_scores.mean()\n",
    "# 0.914169880747776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#fastlogist.fit(X_train_new8, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred8 = fastlogist.predict_proba(X_test_new8)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred8, 'subm_self8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher.fit(X_train_new8, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher.best_score_, logit_grid_searcher.best_params_\n",
    "# (0.9081530648461433, {'C': 0.21544346900318834})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alice_web_count_score = {}\n",
    "\n",
    "count = 0\n",
    "for key, val in alice_web_count_statistic.items():\n",
    "    count += val\n",
    "    pass\n",
    "for key, val in alice_web_count_statistic.items():\n",
    "    alice_web_count_score[key] = val * 1.0 / count\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alice_web_score = {}\n",
    "count = 0\n",
    "\n",
    "for key, val in alice_web_statistic.items():\n",
    "    count += val\n",
    "    pass\n",
    "for key, val in alice_web_statistic.items():\n",
    "    alice_web_score[key] = val * 1.0 / count\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_score(row):\n",
    "    score = 0\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            if row[i] in alice_web_count_score:\n",
    "                score += alice_web_count_score[row[i]]\n",
    "            pass\n",
    "        pass\n",
    "    return score\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_count_score(row):\n",
    "    count = 0\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            count += 1\n",
    "            pass\n",
    "        pass\n",
    "    if count in alice_web_count_score:\n",
    "        return alice_web_count_score[count]\n",
    "    else:\n",
    "        return 0\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linspace(0.1, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher3 = GridSearchCV(estimator=logit, param_grid={'C': np.linspace(0.1, 1, 10)},\n",
    "#                                  scoring='accuracy', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher3.fit(X_train_new10, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher3.best_score_, logit_grid_searcher3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred10 = logit_grid_searcher3.predict_proba(X_test_new10)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred10, 'subm_self10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher4 = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "#                                  scoring='accuracy', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher4.fit(X_train_new10, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher4.best_score_, logit_grid_searcher4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred11 = logit_grid_searcher4.predict_proba(X_test_new10)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred11, 'subm_self11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.logspace(-2, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.logspace(-3, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_values = np.logspace(-3, 1, 10)\n",
    "\n",
    "#logit_grid_searcher_1 = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "#                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_1.fit(X_train_new10, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_1.best_score_, logit_grid_searcher_1.best_params_\n",
    "# 0.913374049587434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher_1.fit(X_train_new1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_1.best_score_, logit_grid_searcher_1.best_params_\n",
    "# 0.9181526261645014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linspace(0.15, 0.25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_2 = GridSearchCV(estimator=logit, param_grid={'C': np.linspace(0.15, 0.25, 10)},\n",
    "#                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher_2.fit(X_train_new1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_2.best_score_, logit_grid_searcher_2.best_params_\n",
    "# (0.9183729937045094, {'C': 0.22777777777777777})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_3 = GridSearchCV(estimator=logit, param_grid={'C': np.linspace(0.22, 0.6, 20)},\n",
    "#                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher_3.fit(X_train_new1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_3.best_score_, logit_grid_searcher_3.best_params_\n",
    "# (0.9183505761017501, {'C': 0.24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_4 = GridSearchCV(estimator=logit, param_grid={'C': np.linspace(0.22, 0.25, 10)},\n",
    "#                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher_4.fit(X_train_new1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_4.best_score_, logit_grid_searcher_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_5 = GridSearchCV(estimator=logit, param_grid={'C': np.linspace(0.223, 0.229, 10)},\n",
    "#                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#logit_grid_searcher_5.fit(X_train_new1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_grid_searcher_5.best_score_, logit_grid_searcher_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_test_pred12 = logit_grid_searcher_5.predict_proba(X_test_new1)[:, 1]\n",
    "#write_to_submission_file(logit_test_pred12, 'subm_self12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature day_of_week, web_unique, time_diff1-10, total_time, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inspire by https://www.kaggle.com/adityaecdrid/initial-eda and https://www.kaggle.com/hakeydotcom/additional-time-features-and-logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optional stop hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_unique(row):\n",
    "    s = set()\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            s.add(row[i])\n",
    "            pass\n",
    "        pass\n",
    "    return len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_time(row):\n",
    "    if len(times) <= 1:\n",
    "        return 0\n",
    "    start = row[times[0]]\n",
    "    end = start\n",
    "    for i in times:\n",
    "        if row[i] == 0:\n",
    "            break\n",
    "            pass\n",
    "        end = row[i]\n",
    "        pass\n",
    "    return (end - start).total_seconds() #/ np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_time(row, f, t):\n",
    "    if len(times) < f or len(times) < t:\n",
    "        return 0\n",
    "    if row[times[f]] == 0 or row[times[t]] == 0:\n",
    "        return 0\n",
    "    return (row[times[t]] - row[times[f]]).total_seconds() #/ np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_11(df, X_sparse):\n",
    "\n",
    "    total_time = df.apply(lambda row: get_total_time(row), axis=1)\n",
    "    \n",
    "    # ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    #total_time_5 = (total_time <= 300).astype('int')\n",
    "    #total_time_10 = ((total_time > 300) & (total_time <= 600)).astype('int')\n",
    "    #total_time_15 = ((total_time > 600) & (total_time <= 900)).astype('int')\n",
    "    #total_time_20 = ((total_time > 900) & (total_time <= 1200)).astype('int')\n",
    "    #total_time_25 = ((total_time > 1200) & (total_time <= 1500)).astype('int')\n",
    "    #total_time_30 = ((total_time > 1500) & (total_time <= 1800)).astype('int')\n",
    "    \n",
    "    #diff_time1 = df.apply(lambda row: get_diff_time(row, 0, 1), axis=1)\n",
    "    #diff_time2 = df.apply(lambda row: get_diff_time(row, 1, 2), axis=1)\n",
    "    #diff_time3 = df.apply(lambda row: get_diff_time(row, 2, 3), axis=1)\n",
    "    #diff_time4 = df.apply(lambda row: get_diff_time(row, 3, 4), axis=1)\n",
    "    #diff_time5 = df.apply(lambda row: get_diff_time(row, 4, 5), axis=1)\n",
    "    #diff_time6 = df.apply(lambda row: get_diff_time(row, 5, 6), axis=1)\n",
    "    #diff_time7 = df.apply(lambda row: get_diff_time(row, 6, 7), axis=1)\n",
    "    #diff_time8 = df.apply(lambda row: get_diff_time(row, 7, 8), axis=1)\n",
    "    #diff_time9 = df.apply(lambda row: get_diff_time(row, 8, 9), axis=1)\n",
    "    \n",
    "    scaler = StandardScaler() \n",
    "    #hour = scaler.fit_transform(hour.values.reshape(-1, 1))\n",
    "    #dayinweek = scaler.fit_transform(dayinweek.values.reshape(-1, 1))\n",
    "    #web_unique = scaler.fit_transform(web_unique.values.reshape(-1, 1))\n",
    "    #total_time = scaler.fit_transform(total_time.values.reshape(-1, 1))\n",
    "    #diff_time1 = scaler.fit_transform(diff_time1.values.reshape(-1, 1))\n",
    "    #diff_time2 = scaler.fit_transform(diff_time2.values.reshape(-1, 1))\n",
    "    #diff_time3 = scaler.fit_transform(diff_time3.values.reshape(-1, 1))\n",
    "    #diff_time4 = scaler.fit_transform(diff_time4.values.reshape(-1, 1))\n",
    "    #diff_time5 = scaler.fit_transform(diff_time5.values.reshape(-1, 1))\n",
    "    #diff_time6 = scaler.fit_transform(diff_time6.values.reshape(-1, 1))\n",
    "    #diff_time7 = scaler.fit_transform(diff_time7.values.reshape(-1, 1))\n",
    "    #diff_time8 = scaler.fit_transform(diff_time8.values.reshape(-1, 1))\n",
    "    #diff_time9 = scaler.fit_transform(diff_time9.values.reshape(-1, 1))\n",
    "    \n",
    "    X = hstack([X_sparse\n",
    "\n",
    "                , total_time.values.reshape(-1, 1)\n",
    "               ])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_web_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alice_web_statistic = {}\n",
    "#alice_web_count_statistic = {}\n",
    "\n",
    "def getwebid_feature(row, outdict):\n",
    "    for i in sites:\n",
    "        webid = row[i]\n",
    "        if webid in outdict:\n",
    "            outdict[webid] = outdict[webid] + 1\n",
    "        else:\n",
    "            outdict[webid] = 1\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "#train_df[train_df['target'] == 1][sites].fillna(0).astype('int').apply(lambda row: getalice_feature(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_webid = {}\n",
    "alice_webid_df = train_df[train_df['target'] == 1][sites].fillna(0).astype('int').apply(lambda row: getwebid_feature(row, alice_webid),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalice_webid = {}\n",
    "nonalice_webid_df = train_df[train_df['target'] == 0][sites].fillna(0).astype('int').apply(lambda row: getwebid_feature(row, nonalice_webid),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alice_webid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41412"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonalice_webid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_webid_set = alice_webid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalice_webid_set = nonalice_webid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'> <class 'dict_keys'>\n"
     ]
    }
   ],
   "source": [
    "print(type(alice_webid_set), type(nonalice_webid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_alice = alice_webid_set - nonalice_webid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only_alice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_value = sorted(alice_webid.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted_by_value[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_by_value\n",
    "alice_top10 = set()\n",
    "alice_top10_total = 0\n",
    "for i in range(0, 10):\n",
    "    alice_top10_total += sorted_by_value[i][1]\n",
    "    alice_top10.add(sorted_by_value[i][0])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8348"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_top10_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21, 22, 29, 75, 76, 77, 80, 81, 82, 879}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_total = 0\n",
    "\n",
    "for key, val in alice_webid.items():\n",
    "    alice_total +=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22970"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalice_top = sorted(nonalice_webid.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonalice_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalice_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalice_top10 = set()\n",
    "nonalice_top10_total = 0\n",
    "for i in range(0, 11):\n",
    "    if nonalice_top[i][0] != 0:\n",
    "        nonalice_top10_total += nonalice_top[i][1]\n",
    "        nonalice_top10.add(nonalice_top[i][0])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21, 22, 23, 29, 52, 167, 778, 780, 782, 812}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonalice_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597536"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonalice_top10_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonalice_total = 0\n",
    "\n",
    "for key, val in nonalice_webid.items():\n",
    "    nonalice_total +=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2512640"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonalice_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mathNonAliceTop10(row):\n",
    "    for i in sites:\n",
    "        if row[i] in nonalice_top10:\n",
    "            return True\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mathAliceTop10(row):\n",
    "    for i in sites:\n",
    "        if row[i] in alice_top10:\n",
    "            return True\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchOnlyAlice(row):\n",
    "    for i in sites:\n",
    "        if row[i] in only_alice:\n",
    "            return True\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_count(row):\n",
    "    count = 0\n",
    "    for i in sites:\n",
    "        if row[i] != 0:\n",
    "            count += 1\n",
    "            pass\n",
    "        pass\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_lastone(df, X_sparse):\n",
    "    #dayinweek = df['time1'].apply(lambda ts: ts.isoweekday())\n",
    "    matchalicewebid = df.apply(lambda row: matchOnlyAlice(row), axis=1).astype('int')\n",
    "    matchalicetop10 = df.apply(lambda row: mathAliceTop10(row), axis=1).astype('int')\n",
    "    matchnonalicetop10 = df.apply(lambda row: mathNonAliceTop10(row), axis=1).astype('int')\n",
    "    #hour = df['time1'].apply(lambda ts: ts.hour)\n",
    "    web_unique = df.apply(lambda row: get_web_unique(row), axis=1)\n",
    "    web_count = df.apply(lambda row: get_web_count(row), axis=1)\n",
    "    \n",
    "    scaler = StandardScaler() \n",
    "    #dayinmonth = scaler.fit_transform(dayinmonth.values.reshape(-1, 1))\n",
    "    #hour = scaler.fit_transform(hour.values.reshape(-1, 1))\n",
    "    #dayinweek = scaler.fit_transform(dayinweek.values.reshape(-1, 1))\n",
    "    web_unique = scaler.fit_transform(web_unique.values.reshape(-1, 1))\n",
    "    web_count = scaler.fit_transform(web_count.values.reshape(-1, 1))\n",
    "    \n",
    "    X = hstack([X_sparse\n",
    "                #, dayinweek.values.reshape(-1, 1)\n",
    "                #, dayinweek[:, :]\n",
    "                , matchalicewebid.values.reshape(-1, 1)\n",
    "                , matchalicetop10.values.reshape(-1, 1)\n",
    "                , matchnonalicetop10.values.reshape(-1, 1)\n",
    "                #, diff_time4[:, :]\n",
    "                #, diff_time5[:, :]\n",
    "                #, diff_time6[:, :]\n",
    "                #, diff_time7[:, :]\n",
    "                #, diff_time8[:, :]\n",
    "                #, diff_time9[:, :]\n",
    "                #, hour.values.reshape(-1, 1)\n",
    "                #, hour[:, :]\n",
    "                #, total_time_30.values.reshape(-1, 1)\n",
    "                #, total_time.values.reshape(-1, 1)\n",
    "                , web_unique[:, :]\n",
    "                , web_count[:, :]\n",
    "               ])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = train_df.fillna(0)\n",
    "new_test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_lastone = add_features_lastone(new_train_df, X_train_new1)\n",
    "X_test_lastone = add_features_lastone(new_test_df, X_test_new1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lastone = LogisticRegression(C=1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(logit_lastone, X_train_lastone, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.89759358, 0.77349503, 0.94366368, 0.98645955, 0.91852612,\n",
       "        0.96931893, 0.96733199, 0.94371164, 0.95489104, 0.94501184]),\n",
       " 0.9300003419280986)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values_lastone = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher_lastone = GridSearchCV(estimator=logit_lastone, param_grid={'C': c_values_lastone},\n",
    "                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 10.7min finished\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=17, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([1.00000e-02, 2.78256e-02, 7.74264e-02, 2.15443e-01, 5.99484e-01,\n",
       "       1.66810e+00, 4.64159e+00, 1.29155e+01, 3.59381e+01, 1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher_lastone.fit(X_train_lastone, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9308925830271153, {'C': 0.5994842503189409})"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher_lastone.best_score_, logit_grid_searcher_lastone.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred_lastone = logit_grid_searcher_lastone.predict_proba(X_test_lastone)[:, 1]\n",
    "write_to_submission_file(logit_test_pred_lastone, 'subm_lastone.csv') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.21544346900318834, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_lastone.fit(X_train_lastone, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit_lastone.predict_proba(X_test_lastone)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'subm_lastone_1.csv') # 0.93843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_time = train_df.fillna(0).apply(lambda row: get_total_time(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_time.iloc[1].total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 0.9164082065409461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (0.9183503264075926, {'C': 0.21544346900318834})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_new12 = add_features_11(train_df.fillna(0), X_train_new1)\n",
    "X_test_new12 = add_features_11(test_df.fillna(0), X_test_new1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver='liblinear'\n",
    "logit12 = LogisticRegression(C=1, random_state=17, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(logit12, X_train_new12, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87785413, 0.75905071, 0.92989561, 0.97860492, 0.90468275,\n",
       "        0.94581241, 0.96286484, 0.92797542, 0.94919461, 0.9407926 ]),\n",
       " 0.9176728004288149)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()\n",
    "# 0.9165846708050015 for 5, 10, 15, 20, 25, 30 total time\n",
    "# 0.9176728004288149 for total time no op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=17, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_new12, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred12_1 = logit.predict_proba(X_test_new12)[:, 1]\n",
    "write_to_submission_file(logit_test_pred12_1, 'subm12_1.csv') # 0.93843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values12 = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher12 = GridSearchCV(estimator=logit, param_grid={'C': c_values12},\n",
    "                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:  8.5min finished\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=17, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'C': array([1.00000e-02, 2.78256e-02, 7.74264e-02, 2.15443e-01, 5.99484e-01,\n",
       "       1.66810e+00, 4.64159e+00, 1.29155e+01, 3.59381e+01, 1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher12.fit(X_train_new12, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9187219397390473, {'C': 0.21544346900318834})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher12.best_score_, logit_grid_searcher12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred12 = logit_grid_searcher12.predict_proba(X_test_new12)[:, 1]\n",
    "write_to_submission_file(logit_test_pred12, 'subm12.csv') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-01-12 08:05:57')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_train_df['time1'].iloc[0]\n",
    "# Timestamp('2013-01-12 08:05:57')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_train_df['time1'].iloc[0].day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-01-12 08:05:57')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_train_df['time1'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `Timestamp` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_time_minute(row):\n",
    "    if len(times) <= 1:\n",
    "        return 0\n",
    "    start = row[times[0]]\n",
    "    end = start\n",
    "    for i in times:\n",
    "        if row[i] == 0:\n",
    "            break\n",
    "            pass\n",
    "        end = row[i]\n",
    "        pass\n",
    "    return ((end - start).total_seconds() + 59) // 60 #/ np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_in_month(dt):\n",
    "    return dt['time1'].date.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_13(df, X_sparse):\n",
    "    dayinweek = df['time1'].apply(lambda ts: ts.isoweekday())\n",
    "    #dayinmonth = df['time1'].apply(lambda ts: ts.day)\n",
    "    web_unique = df.apply(lambda row: get_web_unique(row), axis=1)\n",
    "    total_time = df.apply(lambda row: get_total_time_minute(row), axis=1)\n",
    "    hour = df['time1'].apply(lambda ts: ts.hour)\n",
    "    \n",
    "    dayinweek_1 = ((dayinweek == 1)).astype('int')\n",
    "    dayinweek_3 = ((dayinweek == 3)).astype('int')\n",
    "    #dayinweek_4_5 = ((dayinweek == 4) | (dayinweek == 5)).astype('int')\n",
    "    #dayinweek_other = ((dayinweek != 4) & (dayinweek != 5) & (dayinweek != 1) & (dayinweek != 2)).astype('int')\n",
    "    \n",
    "    hourin_8 = ((hour == 8)).astype('int')\n",
    "    hourin_12_15 = ((hour == 14) | (hour == 15)).astype('int')\n",
    "    hourin_16_17_18 = ((hour == 16) | (hour == 17) | (hour == 18)).astype('int')\n",
    "    #hourin_other = ((dayinweek != 12) & (dayinweek != 13) & (dayinweek != 16) & (dayinweek != 17) & (dayinweek != 18)).astype('int')\n",
    "    \n",
    "    total_time_5 = ((total_time <= 10)).astype('int')\n",
    "    total_time_10 = ((total_time <= 10) & (total_time > 10)).astype('int')\n",
    "\n",
    "    scaler = StandardScaler() \n",
    "    #dayinmonth = scaler.fit_transform(dayinmonth.values.reshape(-1, 1))\n",
    "    #hour = scaler.fit_transform(hour.values.reshape(-1, 1))\n",
    "    #dayinweek = scaler.fit_transform(dayinweek.values.reshape(-1, 1))\n",
    "\n",
    "    \n",
    "    X = hstack([X_sparse\n",
    "                #, dayinweek.values.reshape(-1, 1)\n",
    "                #, hour.values.reshape(-1, 1)\n",
    "                #, web_unique.values.reshape(-1, 1)\n",
    "                , dayinweek_1.values.reshape(-1, 1)\n",
    "                , dayinweek_3.values.reshape(-1, 1)\n",
    "                #, dayinweek_other.values.reshape(-1, 1)\n",
    "                \n",
    "                , hourin_8.values.reshape(-1, 1)\n",
    "                , hourin_12_15.values.reshape(-1, 1)\n",
    "                , hourin_16_17_18.values.reshape(-1, 1)\n",
    "                \n",
    "                , total_time_5.values.reshape(-1, 1)\n",
    "                , total_time_10.values.reshape(-1, 1)\n",
    "                #, hourin_other.values.reshape(-1, 1)\n",
    "                #, total_time.values.reshape(-1, 1)\n",
    "                #, web_unique[:, :]\n",
    "                #, total_time[:, :]\n",
    "                #, dayinweek[:, :]\n",
    "                #, diff_time1[:, :]\n",
    "                #, diff_time2[:, :]\n",
    "                #, diff_time3[:, :]\n",
    "                #, diff_time4[:, :]\n",
    "                #, diff_time5[:, :]\n",
    "                #, diff_time6[:, :]\n",
    "                #, diff_time7[:, :]\n",
    "                #, diff_time8[:, :]\n",
    "                #, diff_time9[:, :]\n",
    "                #, hour.values.reshape(-1, 1)\n",
    "                #, hour[:, :]\n",
    "                #, total_time_5.values.reshape(-1, 1)\n",
    "                #, total_time_10.values.reshape(-1, 1)\n",
    "                #, total_time_15.values.reshape(-1, 1)\n",
    "                #, total_time_20.values.reshape(-1, 1)\n",
    "                #, total_time_25.values.reshape(-1, 1)\n",
    "                #, total_time_30.values.reshape(-1, 1)\n",
    "                #, total_time.values.reshape(-1, 1)\n",
    "                #, diff_time1.values.reshape(-1, 1)\n",
    "                #, diff_time2.values.reshape(-1, 1)\n",
    "                #, diff_time3.values.reshape(-1, 1)\n",
    "                #, diff_time4.values.reshape(-1, 1)\n",
    "                #, diff_time5.values.reshape(-1, 1)\n",
    "                #, diff_time6.values.reshape(-1, 1)\n",
    "                #, diff_time7.values.reshape(-1, 1)\n",
    "                #, diff_time8.values.reshape(-1, 1)\n",
    "                #, diff_time9.values.reshape(-1, 1)\n",
    "                #, dayinmonth.values.reshape(-1, 1)\n",
    "                #, dayinmonth[:, :]\n",
    "               ])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_new13 = add_features_13(new_train_df, X_train)\n",
    "X_test_new13 = add_features_13(new_test_df, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit13 = LogisticRegression(C=0.21544346900318834, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(logit, X_train_new13, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.85419456, 0.75904635, 0.97217055, 0.97229386, 0.91461613,\n",
       "        0.97553383, 0.89916641, 0.94487496, 0.87322648, 0.97470356]),\n",
       " 0.9139826692565496)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()\n",
    "# 0.9183928162548293\n",
    "# 0.9212810466948731 use logit13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.21544346900318834, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit13.fit(X_train_new13, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred13_1 = logit13.predict_proba(X_test_new13)[:, 1]\n",
    "write_to_submission_file(logit_test_pred13_1, 'subm13_1.csv') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values13 = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher13 = GridSearchCV(estimator=logit, param_grid={'C': c_values13},\n",
    "                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=17, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([1.00000e-02, 2.78256e-02, 7.74264e-02, 2.15443e-01, 5.99484e-01,\n",
       "       1.66810e+00, 4.64159e+00, 1.29155e+01, 3.59381e+01, 1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher13.fit(X_train_new13, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9187219397390473, {'C': 0.21544346900318834})"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher12.best_score_, logit_grid_searcher12.best_params_\n",
    "# (0.9187219397390473, {'C': 0.21544346900318834})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit14 = LogisticRegression(C=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values14 = np.logspace(-2, 2, 20)\n",
    "\n",
    "logit_grid_searcher14 = GridSearchCV(estimator=logit14, param_grid={'C': c_values14},\n",
    "                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 20.2min finished\n",
      "d:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([1.00000e-02, 1.62378e-02, 2.63665e-02, 4.28133e-02, 6.95193e-02,\n",
       "       1.12884e-01, 1.83298e-01, 2.97635e-01, 4.83293e-01, 7.84760e-01,\n",
       "       1.27427e+00, 2.06914e+00, 3.35982e+00, 5.45559e+00, 8.85867e+00,\n",
       "       1.43845e+01, 2.33572e+01, 3.79269e+01, 6.15848e+01, 1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher14.fit(X_train_new13, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.913085746373354,\n",
       " {'C': 0.18329807108324356},\n",
       " LogisticRegression(C=0.18329807108324356, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "           solver='warn', tol=0.0001, verbose=0, warm_start=False),\n",
       " {'C': 0.18329807108324356})"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher14.best_score_, logit_grid_searcher14.best_params_, logit_grid_searcher14.best_estimator_, logit_grid_searcher14.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred14 = logit_grid_searcher14.predict_proba(X_test_new13)[:, 1]\n",
    "write_to_submission_file(logit_test_pred14, 'subm13.csv') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(rf, X_train_new13, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.66537805, 0.59268359, 0.73395755, 0.86501889, 0.64571057,\n",
       "        0.71369666, 0.88386354, 0.61923017, 0.73335726, 0.70858517]),\n",
       " 0.7161481442263696)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 50026 features per sample; expecting 50009",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-288-c03cb5d2a87a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogit_test_pred15\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_grid_searcher12\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_new13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwrite_to_submission_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit_test_pred15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subm15.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \"\"\"\n\u001b[0;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1405\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[0;32m   1406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \"\"\"\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 262\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 50026 features per sample; expecting 50009"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
